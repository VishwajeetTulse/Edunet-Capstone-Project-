{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f76124cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.optimize import minimize\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator, FormatStrFormatter, PercentFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import Adam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from colorama import Fore, Style\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import VotingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d432172",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30582b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 5/5 [00:58<00:00, 11.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train QWK --> 0.7561\n",
      "Mean Validation QWK ---> 0.3950\n",
      "----> || Optimized QWK SCORE :: \u001b[36m\u001b[1m 0.453\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to submission.csv\n",
      "Retraining model on full dataset...\n",
      "Saving model and artifacts...\n",
      "Model, mappings, and thresholds saved.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016bb22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001f3379</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0038ba98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0068a485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0069fbed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0083e397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0087dd65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00abe655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00ae59c9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00af6387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00bd4359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00c0cd71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00d56d4b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00d9913d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00e6167c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00ebc35d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  sii\n",
       "0   00008ff9    1\n",
       "1   000fd460    0\n",
       "2   00105258    0\n",
       "3   00115b9f    0\n",
       "4   0016bb22    0\n",
       "5   001f3379    1\n",
       "6   0038ba98    0\n",
       "7   0068a485    0\n",
       "8   0069fbed    1\n",
       "9   0083e397    0\n",
       "10  0087dd65    0\n",
       "11  00abe655    0\n",
       "12  00ae59c9    2\n",
       "13  00af6387    1\n",
       "14  00bd4359    1\n",
       "15  00c0cd71    1\n",
       "16  00d56d4b    0\n",
       "17  00d9913d    0\n",
       "18  00e6167c    0\n",
       "19  00ebc35d    1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('edunet-project-dataset/train.csv')\n",
    "test = pd.read_csv('edunet-project-dataset/test.csv')\n",
    "sample = pd.read_csv('edunet-project-dataset/sample_submission.csv')\n",
    "\n",
    "def process_file(filename, dirname):\n",
    "    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "    df.drop('step', axis=1, inplace=True)\n",
    "    return df.describe().values.reshape(-1), filename.split('=')[1]\n",
    "\n",
    "def load_time_series(dirname) -> pd.DataFrame:\n",
    "    ids = os.listdir(dirname)\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    \n",
    "    stats, indexes = zip(*results)\n",
    "    \n",
    "    df = pd.DataFrame(stats, columns=[f\"stat_{i}\" for i in range(len(stats[0]))])\n",
    "    df['id'] = indexes\n",
    "    return df\n",
    "        \n",
    "train_ts = load_time_series(\"edunet-project-dataset/series_train.parquet\")\n",
    "test_ts = load_time_series(\"edunet-project-dataset/series_test.parquet\")\n",
    "\n",
    "time_series_cols = train_ts.columns.tolist()\n",
    "time_series_cols.remove(\"id\")\n",
    "\n",
    "train = pd.merge(train, train_ts, how=\"left\", on='id')\n",
    "test = pd.merge(test, test_ts, how=\"left\", on='id')\n",
    "\n",
    "train = train.drop('id', axis=1)\n",
    "test = test.drop('id', axis=1)   \n",
    "\n",
    "featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "                'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n",
    "                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "                'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n",
    "                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "                'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n",
    "                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "                'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n",
    "                'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw',\n",
    "                'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n",
    "                'PreInt_EduHx-computerinternet_hoursday', 'sii']\n",
    "\n",
    "featuresCols += time_series_cols\n",
    "\n",
    "train = train[featuresCols]\n",
    "train = train.dropna(subset='sii')\n",
    "\n",
    "cat_c = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', \n",
    "          'Fitness_Endurance-Season', 'FGC-Season', 'BIA-Season', \n",
    "          'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']\n",
    "\n",
    "def update(df):\n",
    "    global cat_c\n",
    "    for c in cat_c: \n",
    "        df[c] = df[c].fillna('Missing')\n",
    "        df[c] = df[c].astype('category')\n",
    "    return df\n",
    "        \n",
    "train = update(train)\n",
    "test = update(test)\n",
    "\n",
    "def create_mapping(column, dataset):\n",
    "    unique_values = dataset[column].unique()\n",
    "    return {value: idx for idx, value in enumerate(unique_values)}\n",
    "\n",
    "all_mappings = {}\n",
    "\n",
    "for col in cat_c:\n",
    "    mapping = create_mapping(col, train)\n",
    "    mappingTe = create_mapping(col, test)\n",
    "    \n",
    "    all_mappings[col] = mapping\n",
    "\n",
    "    # Modified lines to fix TypeError with Categorical data\n",
    "    train[col] = train[col].astype(object).replace(mapping).astype(int)\n",
    "    test[col] = test[col].astype(object).replace(mappingTe).astype(int)\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(oof_non_rounded < thresholds[0], 0,\n",
    "                    np.where(oof_non_rounded < thresholds[1], 1,\n",
    "                             np.where(oof_non_rounded < thresholds[2], 2, 3)))\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)\n",
    "\n",
    "def TrainML(model_class, test_data):\n",
    "    X = train.drop(['sii'], axis=1)\n",
    "    y = train['sii']\n",
    "\n",
    "    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    train_S = []\n",
    "    test_S = []\n",
    "    \n",
    "    oof_non_rounded = np.zeros(len(y), dtype=float) \n",
    "    oof_rounded = np.zeros(len(y), dtype=int) \n",
    "    test_preds = np.zeros((len(test_data), n_splits))\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = clone(model_class)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        oof_non_rounded[test_idx] = y_val_pred\n",
    "        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "        oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "        train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n",
    "        val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "\n",
    "        train_S.append(train_kappa)\n",
    "        test_S.append(val_kappa)\n",
    "        \n",
    "        test_preds[:, fold] = model.predict(test_data)\n",
    "        \n",
    "        print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n",
    "    print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f}\")\n",
    "\n",
    "    KappaOPtimizer = minimize(evaluate_predictions,\n",
    "                              x0=[0.5, 1.49, 2.5], args=(y, oof_non_rounded), \n",
    "                              method='Nelder-Mead')\n",
    "    assert KappaOPtimizer.success, \"Optimization did not converge.\"\n",
    "    thresholds = KappaOPtimizer.x\n",
    "    \n",
    "    oof_tuned = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    tKappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "    print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n",
    "\n",
    "    fold_weights = [1.25, 1.0, 1.0, 1.0, 1.0]\n",
    "    tpm = test_preds.dot(fold_weights) / np.sum(fold_weights)\n",
    "    tpTuned = threshold_Rounder(tpm, thresholds)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'id': sample['id'],\n",
    "        'sii': tpTuned\n",
    "    })\n",
    "\n",
    "    return submission, thresholds\n",
    "\n",
    "# Model parameters for LightGBM\n",
    "Params = {\n",
    "    'learning_rate': 0.046,\n",
    "    'max_depth': 12,\n",
    "    'num_leaves': 478,\n",
    "    'min_data_in_leaf': 13,\n",
    "    'feature_fraction': 0.893,\n",
    "    'bagging_fraction': 0.784,\n",
    "    'bagging_freq': 4,\n",
    "    'lambda_l1': 10,  # Increased from 6.59\n",
    "    'lambda_l2': 0.01  # Increased from 2.68e-06\n",
    "}\n",
    "\n",
    "\n",
    "# XGBoost parameters\n",
    "XGB_Params = {\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'n_estimators': 200,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 1,  # Increased from 0.1\n",
    "    'reg_lambda': 5,  # Increased from 1\n",
    "    'random_state': SEED\n",
    "}\n",
    "\n",
    "\n",
    "CatBoost_Params = {\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'iterations': 200,\n",
    "    'random_seed': SEED,\n",
    "    'cat_features': cat_c,\n",
    "    'verbose': 0,\n",
    "    'l2_leaf_reg': 10  # Increase this value\n",
    "}\n",
    "\n",
    "# Create model instances\n",
    "Light = LGBMRegressor(**Params, random_state=SEED, verbose=-1, n_estimators=300)\n",
    "XGB_Model = XGBRegressor(**XGB_Params)\n",
    "CatBoost_Model = CatBoostRegressor(**CatBoost_Params)\n",
    "\n",
    "# Combine models using Voting Regressor\n",
    "model = VotingRegressor(estimators=[\n",
    "    ('lightgbm', Light),\n",
    "    ('xgboost', XGB_Model),\n",
    "    ('catboost', CatBoost_Model)\n",
    "])\n",
    "\n",
    "# Train the ensemble model\n",
    "Submission2, thresholds = TrainML(model, test)\n",
    "\n",
    "# Save submission\n",
    "Submission2.to_csv('submission.csv', index=False)\n",
    "print('Submission saved to submission.csv')\n",
    "\n",
    "# Retrain and Save Model\n",
    "print(\"Retraining model on full dataset...\")\n",
    "X = train.drop(['sii'], axis=1)\n",
    "y = train['sii']\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"Saving model and artifacts...\")\n",
    "joblib.dump(model, 'model.pkl')\n",
    "joblib.dump(all_mappings, 'mappings.pkl')\n",
    "joblib.dump(thresholds, 'thresholds.pkl')\n",
    "joblib.dump(X.columns.tolist(), 'features.pkl')  # Saving feature names\n",
    "print(\"Model, mappings, and thresholds saved.\")\n",
    "\n",
    "Submission2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
